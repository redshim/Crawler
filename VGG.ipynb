{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redshim/Crawler/blob/master/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA_Zety3T19-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "04161637-b116-4861-ff2d-22a62bdacb94"
      },
      "source": [
        "\"\"\"\n",
        "Fashion Mnist VGG\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn import datasets, model_selection\n",
        "\n",
        "# 문제\n",
        "# 패션 mnist 데이터셋에 대해 85% 이상의 모델을 만드세요\n",
        "\n",
        "def get_fashion_mnist():\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    print(x_train.shape, y_train.shape) # (60000, 784) (60000, 10)\n",
        "    print(y_train[0]) #9\n",
        "\n",
        "    y_train = np.int32(y_train)\n",
        "    y_test = np.int32(y_test)\n",
        "\n",
        "    x_train     = x_train.reshape(-1,784)\n",
        "    x_test      = x_test.reshape(-1, 784)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "#Lenet5를 이름만 변경하여 사용\n",
        "def my_cnn(ph_x):\n",
        "    # ph_x = 100,784\n",
        "    # CONV Layer----------------------------------------------------------#\n",
        "    w1 = tf.get_variable(name='w1',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[5, 5, 1, 6]) # filter width , width, depth, filter\n",
        "\n",
        "    b1 = tf.Variable(tf.zeros([6],dtype=tf.float32))\n",
        "\n",
        "    w2 = tf.get_variable(name='w2',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[5, 5, 6, 16]) # width , width, depth(채널), filter\n",
        "\n",
        "    b2 = tf.Variable(tf.zeros([16],dtype=tf.float32))\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    w3 = tf.get_variable(name='w3',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[5*5*16,120])\n",
        "    b3 = tf.Variable(tf.zeros([120],dtype=tf.float32))\n",
        "\n",
        "    w4 = tf.get_variable(name='w4',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[120,84])\n",
        "    b4 = tf.Variable(tf.zeros([84],dtype=tf.float32))\n",
        "\n",
        "    w5 = tf.get_variable(name='w5',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[84,10])\n",
        "    b5 = tf.Variable(tf.zeros([10],dtype=tf.float32))\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    # Tensorflow는 4차원으로 전달해야함 strides\n",
        "    # c1 = tf.nn.conv2d(ph_x,\n",
        "    #                   filter=w1,\n",
        "    #                   strides=[1,1,1,1],\n",
        "    #                   padding='SAME')\n",
        "    #\n",
        "    # r1 = tf.nn.relu(c1 + b1)\n",
        "    # p1 = tf.nn.max_pool2d(r1,\n",
        "    #                       ksize=[1,2,2,1],\n",
        "    #                       strides=[1,2,2,1],\n",
        "    #                       padding='SAME') # 나누어떨어지지않을때\n",
        "\n",
        "    input = tf.reshape(ph_x, shape=[-1, 28,28,1])\n",
        "\n",
        "    c1 = tf.nn.conv2d(input, w1,[1, 1, 1, 1],'SAME')\n",
        "    r1 = tf.nn.relu(c1 + b1)\n",
        "    p1 = tf.nn.max_pool2d(r1,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "\n",
        "    c2 = tf.nn.conv2d(p1, w2,[1, 1, 1, 1],'VALID')\n",
        "    r2 = tf.nn.relu(c2 + b2)\n",
        "    p2 = tf.nn.max_pool2d(r2,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    # 3차원을 2차원으로 변경\n",
        "    flat = tf.reshape(p2,shape=[-1, 400]) # -1은 크기를 알아서 설정\n",
        "\n",
        "    # print(c1.shape)\n",
        "    # print(p1.shape)\n",
        "    # print(c2.shape)\n",
        "    # print(p2.shape)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    # (?, 120) = (?, 400) @ (400, 120)\n",
        "    z3 = tf.matmul(flat, w3) + b3\n",
        "    r3 = tf.nn.relu(z3)\n",
        "    d3 = tf.nn.dropout(r3,keep_prob=0.7)\n",
        "\n",
        "\n",
        "    # (?, 84) = (?, 120) @ (120, 84)\n",
        "    z4 = tf.matmul(d3, w4) + b4\n",
        "    r4 = tf.nn.relu(z4)\n",
        "\n",
        "    # (?, 10) = (?, 84) @ (84, 10)\n",
        "    z5 = tf.matmul(r4, w5) + b5\n",
        "\n",
        "    # z3 = tf.nn.dropout(z3, keep_prob=0.8)\n",
        "    hx = tf.nn.softmax(z5)\n",
        "\n",
        "    return z5, hx\n",
        "\n",
        "# def my_vgg(ph_x):\n",
        "#     # ph_x = 100,784\n",
        "#     # CONV Layer1----------------------------------------------------------#\n",
        "#     w1 = tf.get_variable(name='w1',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 1, 64]) # filter width , width, depth, filter\n",
        "#\n",
        "#     b1 = tf.Variable(tf.zeros([64],dtype=tf.float32))\n",
        "#\n",
        "#     # CONV Layer2----------------------------------------------------------#\n",
        "#     w2 = tf.get_variable(name='w2',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 64, 64]) # width , width, depth(채널), filter\n",
        "#\n",
        "#     b2 = tf.Variable(tf.zeros([64],dtype=tf.float32))\n",
        "#\n",
        "#     # CONV Layer3----------------------------------------------------------#\n",
        "#     w3 = tf.get_variable(name='w3',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 64, 128]) # width , width, depth(채널), filter\n",
        "#\n",
        "#     b3 = tf.Variable(tf.zeros([128],dtype=tf.float32))\n",
        "#\n",
        "#     # CONV Layer4----------------------------------------------------------#\n",
        "#     w4 = tf.get_variable(name='w4',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 128, 128]) # width , width, depth(채널), filter\n",
        "#\n",
        "#     b4 = tf.Variable(tf.zeros([128],dtype=tf.float32))\n",
        "#\n",
        "#\n",
        "#     # CONV Layer5----------------------------------------------------------#\n",
        "#     w5 = tf.get_variable(name='w5',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 128, 256]) # width , width, depth(채널), filter\n",
        "#\n",
        "#     b5 = tf.Variable(tf.zeros([256],dtype=tf.float32))\n",
        "#     # CONV Layer6----------------------------------------------------------#\n",
        "#     w6 = tf.get_variable(name='w6',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 256, 256]) # width , width, depth(채널), filter\n",
        "#\n",
        "#     b6 = tf.Variable(tf.zeros([256],dtype=tf.float32))\n",
        "#     # CONV Layer7----------------------------------------------------------#\n",
        "#     w7 = tf.get_variable(name='w7',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 256, 256]) # width , width, depth(채널), filter\n",
        "#     b7 = tf.Variable(tf.zeros([256],dtype=tf.float32))\n",
        "#\n",
        "#     # CONV Layer8----------------------------------------------------------#\n",
        "#     w8 = tf.get_variable(name='w8',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 256, 512]) # width , width, depth(채널), filter\n",
        "#     b8 = tf.Variable(tf.zeros([512],dtype=tf.float32))\n",
        "#     # CONV Layer9----------------------------------------------------------#\n",
        "#     w9 = tf.get_variable(name='w9',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 512, 512]) # width , width, depth(채널), filter\n",
        "#     b9 = tf.Variable(tf.zeros([512],dtype=tf.float32))\n",
        "#     # CONV Layer10----------------------------------------------------------#\n",
        "#     w10 = tf.get_variable(name='w10',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 512, 512]) # width , width, depth(채널), filter\n",
        "#     b10 = tf.Variable(tf.zeros([512],dtype=tf.float32))\n",
        "#     # CONV Layer11---------------------------------------------------------#\n",
        "#     w11 = tf.get_variable(name='w11',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[3, 3, 512, 512]) # width , width, depth(채널), filter\n",
        "#     b11 = tf.Variable(tf.zeros([512],dtype=tf.float32))\n",
        "#\n",
        "#     # -------------------------------------------------------------------#\n",
        "#     w12 = tf.get_variable(name='w12',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[7*7*512,4096])\n",
        "#     b12 = tf.Variable(tf.zeros([4096],dtype=tf.float32))\n",
        "#\n",
        "#     w13 = tf.get_variable(name='w13',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[4096,4096])\n",
        "#     b13 = tf.Variable(tf.zeros([4096],dtype=tf.float32))\n",
        "#\n",
        "#     w14 = tf.get_variable(name='w14',\n",
        "#                         dtype=tf.float32,\n",
        "#                         initializer=tf.glorot_normal_initializer,\n",
        "#                         shape=[4096,10])\n",
        "#     b14 = tf.Variable(tf.zeros([10],dtype=tf.float32))\n",
        "#\n",
        "#     # -------------------------------------------------------------------#\n",
        "#     # Tensorflow는 4차원으로 전달해야함 strides\n",
        "#     # c1 = tf.nn.conv2d(ph_x,\n",
        "#     #                   filter=w1,\n",
        "#     #                   strides=[1,1,1,1],\n",
        "#     #                   padding='SAME')\n",
        "#     #\n",
        "#     # r1 = tf.nn.relu(c1 + b1)\n",
        "#     # p1 = tf.nn.max_pool2d(r1,\n",
        "#     #                       ksize=[1,2,2,1],\n",
        "#     #                       strides=[1,2,2,1],\n",
        "#     #                       padding='SAME') # 나누어떨어지지않을때\n",
        "#\n",
        "#     input = tf.reshape(ph_x, shape=[-1, 28,28,1])\n",
        "#\n",
        "#     c1 = tf.nn.conv2d(input, w1,[1, 1, 1, 1],'SAME')\n",
        "#     r1 = tf.nn.relu(c1 + b1)\n",
        "#     c2 = tf.nn.conv2d(r1   , w2,[1, 1, 1, 1],'SAME')\n",
        "#     r2 = tf.nn.relu(c2 + b2)\n",
        "#     p1 = tf.nn.max_pool2d(r2,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "#\n",
        "#     # print('c1 ',c1.shape)\n",
        "#     # print('c2 ',c2.shape)\n",
        "#     # print('p2 ',p1.shape)\n",
        "#     # exit(-1)\n",
        "#\n",
        "#     c3 = tf.nn.conv2d(p1, w3,[1, 1, 1, 1],'SAME')\n",
        "#     r3 = tf.nn.relu(c3 + b3)\n",
        "#     c4 = tf.nn.conv2d(r3   , w4,[1, 1, 1, 1],'SAME')\n",
        "#     r4 = tf.nn.relu(c4 + b4)\n",
        "#     p2 = tf.nn.max_pool2d(r4,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "#\n",
        "#\n",
        "#     # c4 = tf.nn.conv2d(p2, w4,[1, 1, 1, 1],'SAME')\n",
        "#     # r4 = tf.nn.relu(c4 + b4)\n",
        "#     # c5 = tf.nn.conv2d(r4   , w5,[1, 1, 1, 1],'SAME')\n",
        "#     # r5 = tf.nn.relu(c5 + b5)\n",
        "#     # c6 = tf.nn.conv2d(r5   , w6,[1, 1, 1, 1],'SAME')\n",
        "#     # r6 = tf.nn.relu(c6 + b6)\n",
        "#     # p3 = tf.nn.max_pool2d(r6,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "#     #\n",
        "#     #\n",
        "#     # c7 = tf.nn.conv2d(p3, w7,[1, 1, 1, 1],'SAME')\n",
        "#     # r7 = tf.nn.relu(c7 + b7)\n",
        "#     # c8 = tf.nn.conv2d(r7   , w8,[1, 1, 1, 1],'SAME')\n",
        "#     # r8 = tf.nn.relu(c8 + b8)\n",
        "#     # c9 = tf.nn.conv2d(r8   , w9,[1, 1, 1, 1],'SAME')\n",
        "#     # r9 = tf.nn.relu(c9 + b9)\n",
        "#     # c10 = tf.nn.conv2d(r9   , w10,[1, 1, 1, 1],'SAME')\n",
        "#     # r10 = tf.nn.relu(c10 + b10)\n",
        "#     # p4 = tf.nn.max_pool2d(r10,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "#     #\n",
        "#     # c11 = tf.nn.conv2d(p4, w11,[1, 1, 1, 1],'SAME')\n",
        "#     # r11 = tf.nn.relu(c11 + b11)\n",
        "#     # p5 = tf.nn.max_pool2d(r11,[1, 2, 2, 1],[1, 2, 2, 1],'SAME')\n",
        "#     #\n",
        "#     #\n",
        "#\n",
        "#\n",
        "#     # -------------------------------------------------------------------#\n",
        "#     # 3차원을 2차원으로 변경\n",
        "#     flat = tf.reshape(p2,shape=[-1, 25088]) # -1은 크기를 알아서 설정\n",
        "#\n",
        "#\n",
        "#     # -------------------------------------------------------------------#\n",
        "#     # (?, 120) = (?, 400) @ (400, 120)\n",
        "#     z12 = tf.matmul(flat, w12) + b12\n",
        "#     r12 = tf.nn.relu(z12)\n",
        "#\n",
        "#     # (?, 84) = (?, 120) @ (120, 84)\n",
        "#     z13 = tf.matmul(r12, w13) + b13\n",
        "#     r13 = tf.nn.relu(z13)\n",
        "#\n",
        "#     # (?, 10) = (?, 84) @ (84, 10)\n",
        "#     z15 = tf.matmul(r13, w14) + b14\n",
        "#\n",
        "#     # z3 = tf.nn.dropout(z3, keep_prob=0.8)\n",
        "#     hx = tf.nn.softmax(z15)\n",
        "#\n",
        "#     return z15, hx\n",
        "\n",
        "def my_vgg_1(ph_x):\n",
        "\n",
        "    def conv_block(input, filter1, filter2, name):\n",
        "        w1 = tf.get_variable(name=name+'/w1',\n",
        "                            dtype=tf.float32,\n",
        "                            initializer=tf.glorot_normal_initializer,\n",
        "                            shape=[3, 3, filter1, filter2]) # filter width , width, depth, filter\n",
        "\n",
        "        b1 = tf.Variable(tf.zeros([filter2],dtype=tf.float32))\n",
        "\n",
        "        w2 = tf.get_variable(name=name+'/w2',\n",
        "                            dtype=tf.float32,\n",
        "                            initializer=tf.glorot_normal_initializer,\n",
        "                            shape=[3, 3, filter2, filter2]) # width , width, depth(채널), filter\n",
        "\n",
        "        b2 = tf.Variable(tf.zeros([filter2],dtype=tf.float32))\n",
        "\n",
        "        c1 = tf.nn.conv2d(input, w1,[1, 1, 1, 1],'SAME')\n",
        "        r1 = tf.nn.relu(c1 + b1)\n",
        "        c2 = tf.nn.conv2d(r1, w2,[1, 1, 1, 1],'SAME')\n",
        "        r2 = tf.nn.relu(c2 + b2)\n",
        "\n",
        "        p3 = tf.nn.max_pool2d(r2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
        "\n",
        "        return p3\n",
        "\n",
        "    input = tf.reshape(ph_x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    conv1 = conv_block(input, 1, 64, 'c1')\n",
        "    conv2 = conv_block(conv1, 64, 128, 'c2')\n",
        "\n",
        "    print(conv2.shape)\n",
        "    _, r, c, d = conv2.shape\n",
        "    # (7,7,128)\n",
        "    flat = tf.reshape(conv2,shape=[-1, r*c*d]) # -1은 크기를 알아서 설정\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    w3 = tf.get_variable(name='w3',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[flat.shape[-1],120])\n",
        "    b3 = tf.Variable(tf.zeros([120],dtype=tf.float32))\n",
        "\n",
        "    w4 = tf.get_variable(name='w4',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[120,84])\n",
        "    b4 = tf.Variable(tf.zeros([84],dtype=tf.float32))\n",
        "\n",
        "    w5 = tf.get_variable(name='w5',\n",
        "                        dtype=tf.float32,\n",
        "                        initializer=tf.glorot_normal_initializer,\n",
        "                        shape=[84,10])\n",
        "    b5 = tf.Variable(tf.zeros([10],dtype=tf.float32))\n",
        "\n",
        "    # -------------------------------------------------------------------#\n",
        "    # (?, 120) = (?, 400) @ (400, 120)\n",
        "    z3 = tf.matmul(flat, w3) + b3\n",
        "    r3 = tf.nn.relu(z3)\n",
        "    d3 = tf.nn.dropout(r3, keep_prob=0.7)\n",
        "\n",
        "    # (?, 84) = (?, 120) @ (120, 84)\n",
        "    z4 = tf.matmul(d3, w4) + b4\n",
        "    r4 = tf.nn.relu(z4)\n",
        "\n",
        "    # (?, 10) = (?, 84) @ (84, 10)\n",
        "    z5 = tf.matmul(r4, w5) + b5\n",
        "\n",
        "    # z3 = tf.nn.dropout(z3, keep_prob=0.8)\n",
        "    hx = tf.nn.softmax(z5)\n",
        "\n",
        "    return z5, hx\n",
        "\n",
        "def show_model(model):\n",
        "    # mnist data set : 28*28 흑백\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = get_fashion_mnist()\n",
        "\n",
        "\n",
        "    ph_x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "    ph_y = tf.placeholder(tf.int32)\n",
        "\n",
        "\n",
        "    ####################################################################\n",
        "    z, hx = model(ph_x)\n",
        "    ####################################################################\n",
        "\n",
        "    # (55000, 10) = (55000, 784) @ (784, 10) + (1,10)\n",
        "    # z = tf.matmul(ph_x, w) + b\n",
        "    # hx = tf.nn.softmax(z)\n",
        "    # hx = tf.add(tf.multiply(w,x),b) # broadcast\n",
        "\n",
        "    # Hypothesis 기반으로 동작하기 때문에 건드릴 필요가 없음\n",
        "\n",
        "    # 왼쪽 아니면 오른쪽을 베타적으로\n",
        "    # loss_i = y * -tf.log(hx) + (1-y) * -tf.log(1-hx)\n",
        "    # loss_i = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_train, logits=z)\n",
        "    # Sparse 버젼을 사용하는 것을 추천함\n",
        "    loss_i = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=ph_y, logits=z)\n",
        "    loss = tf.reduce_mean(loss_i)\n",
        "\n",
        "    # optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "    optimizer = tf.train.AdamOptimizer(0.001)\n",
        "    train = optimizer.minimize(loss)\n",
        "\n",
        "    # Train\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # mini batch\n",
        "    epochs = 10\n",
        "    batch_size = 100\n",
        "    n_iteration = int(len(x_train)/batch_size)\n",
        "\n",
        "\n",
        "    for i in range(epochs):\n",
        "        total = 0\n",
        "        for j in range(n_iteration):\n",
        "            n1 = j * batch_size\n",
        "            n2 = n1 + batch_size\n",
        "            # print('number of iteration : ', j, 'start :',n1, ' end : ',n2)\n",
        "\n",
        "            xx = x_train[n1:n2]\n",
        "            yy = y_train[n1:n2]\n",
        "\n",
        "            sess.run(train, feed_dict={ph_x:xx, ph_y:yy})\n",
        "            total += sess.run(loss, {ph_x:xx , ph_y:yy})\n",
        "            print('.',end='')\n",
        "\n",
        "        print(i, total /n_iteration)\n",
        "\n",
        "    # collection * 는 unpacking list\n",
        "    # 가장 큰숫자위치 FInding\n",
        "\n",
        "    preds = sess.run(hx, {ph_x: x_test})\n",
        "    preds_arg = np.argmax(preds, axis=1) # 차원을 따라서 계산\n",
        "\n",
        "    print(preds)\n",
        "    print(preds_arg)\n",
        "\n",
        "    print('accuracy', np.mean(preds_arg==y_test))\n",
        "\n",
        "    sess.close()\n",
        "\n",
        "# show_model(my_cnn)\n",
        "# accuracy 0.8613\n",
        "\n",
        "show_model(my_vgg_1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n",
            "9\n",
            "(?, 7, 7, 128)\n",
            "WARNING:tensorflow:From <ipython-input-1-a211cc2c4ab8>:356: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................0 0.549867160047094\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................1 0.2901010873665412\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................2 0.24051729895174503\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................3 0.20806890825430552\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................4 0.18722162059197822\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................5 0.16878841553504267\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................6 0.15632680537799995\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................7 0.14413225130488475\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................8 0.13221347405264774\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................9 0.12471674262235562\n",
            "[[5.2685287e-13 1.6028592e-16 6.6648128e-12 ... 3.4660604e-07\n",
            "  1.7701820e-15 9.9999928e-01]\n",
            " [2.0477928e-05 1.3081421e-11 9.9991763e-01 ... 2.2002941e-15\n",
            "  4.2706976e-13 2.3627307e-17]\n",
            " [1.3448954e-26 1.0000000e+00 8.1638441e-32 ... 1.7480260e-22\n",
            "  1.1097704e-29 2.6730005e-27]\n",
            " ...\n",
            " [4.0152817e-20 4.9691769e-19 4.4773031e-20 ... 1.9027193e-22\n",
            "  1.0000000e+00 2.7365552e-20]\n",
            " [1.6457674e-23 1.0000000e+00 6.0539785e-24 ... 6.7632176e-23\n",
            "  2.6111429e-25 8.5218140e-27]\n",
            " [8.8486915e-05 4.9351825e-06 9.6492244e-05 ... 6.8636634e-04\n",
            "  2.3018476e-05 1.2684091e-04]]\n",
            "[9 2 1 ... 8 1 5]\n",
            "accuracy 0.9126\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}